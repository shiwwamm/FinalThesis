# -*- coding: utf-8 -*-
"""FInal thesis notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1U52eoSvxxHEpwvWSUDCN9lqzIloO6snW
"""

### Downloads

!pip install -q torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.9.1+cu128.html
!pip install -q torch-geometric

### IMPORTS

import os, numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns
import igraph as ig, gymnasium as gym, torch, torch.nn as nn, torch_geometric.nn as pyg_nn
from gymnasium import spaces
from stable_baselines3 import DQN
from stable_baselines3.common.torch_layers import BaseFeaturesExtractor
from tqdm import tqdm
import random, warnings
warnings.filterwarnings("ignore")

### Mount Drive

from google.colab import drive
drive.mount('/content/drive')

### Import graphs from drive

GRAPH_DIR = "/content/drive/MyDrive/real_world_topologies"
topo = {
    # Small networks (≤ 30 nodes)
    "Abilene": "Abilene.graphml",
    "Heanet": "Heanet.graphml",
    "Nsfcnet": "Nsfcnet.graphml",
    "Cesnet1993": "Cesnet1993.graphml",
    "Singaren": "Singaren.graphml",
    "Arpanet19706": "Arpanet19706.graphml",
    "Cesnet1997": "Cesnet1997.graphml",
    "Eenet": "Eenet.graphml",
    "Twaren": "Twaren.graphml",
    "Atmnet": "Atmnet.graphml",

    # Medium networks (30-100 nodes)
    "Geant2012": "Geant2012.graphml",
    "Chinanet": "Chinanet.graphml",
    "Surfnet": "Surfnet.graphml",
    "Uunet": "Uunet.graphml",
    "Ntt": "Ntt.graphml",
    "BtNorthAmerica": "BtNorthAmerica.graphml",
    "Palmetto": "Palmetto.graphml",
    "SwitchL3": "SwitchL3.graphml",
    "DeutscheTelekom": "DeutscheTelekom.graphml",
    "Iij": "Iij.graphml",

    # Large networks (> 100 nodes)
    "Interoute": "Interoute.graphml",
    "Colt": "Colt.graphml",
    "GtsCe": "GtsCe.graphml",
    "TataNld": "TataNld.graphml",
    "UsCarrier": "UsCarrier.graphml",
    "Deltacom": "Deltacom.graphml",
    "Ion": "Ion.graphml",
    "Pern": "Pern.graphml",
    "Cogentco": "Cogentco.graphml",
    "DialtelecomCz": "DialtelecomCz.graphml",
}
GRAPH_FILES = [os.path.join(GRAPH_DIR, fname) for fname in topo.values()]



### CODE

# ==============================================================
# MASTER'S THESIS – FINAL RL-ONLY EXPERIMENT (30 TOPOLOGIES)
# Methods:
#   - IVI-Reduce     : true Salavaty IVI
#   - NNSI-Reduce    : true NNSI
#   - HYBRID (γ = 5) : λ₂-safe IVI (reduce max IVI, penalize λ₂ drop)
#
# Budget (edges to add):
#   B(N,M) = clamp( ceil(0.15 * N),  2,  min( ceil(0.1 * M), 20 ) )
#
# Metrics per graph:
#   - λ₂ (algebraic connectivity)
#   - MinCut
#   - GCC_5% (post-attack giant component)
#   - ASPL (average shortest path)
#   - Diameter
#   - ArticulationPoints
#   - Bridges
#   - BetCentralization
#   - NatConnectivity
#
# Output:
#   - CSV saved to Drive: /content/drive/MyDrive/thesis_rl_multimetric_30graphs.csv
# ==============================================================

# !pip install -q python-igraph "gymnasium>=0.29.0" "stable-baselines3[extra]" \
#     torch torch-geometric pandas seaborn matplotlib tqdm

import os, numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns
import igraph as ig, gymnasium as gym, torch, torch.nn as nn, torch_geometric.nn as pyg_nn
from gymnasium import spaces
from stable_baselines3 import DQN
from stable_baselines3.common.torch_layers import BaseFeaturesExtractor
from tqdm import tqdm
import random, warnings
warnings.filterwarnings("ignore")

# --------------------- REPRODUCIBILITY ---------------------
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(SEED)

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using {DEVICE} | Seed: {SEED}")

# --------------------- MOUNT DRIVE ---------------------
# from google.colab import drive
# drive.mount('/content/drive')

# --------------------- GRAPH LOADING ---------------------
GRAPH_DIR = "/content/drive/MyDrive/real_world_topologies"
topo = {
    # Small networks (≤ 30 nodes)
    "Abilene": "Abilene.graphml",
    "Heanet": "Heanet.graphml",
    "Nsfcnet": "Nsfcnet.graphml",
    "Cesnet1993": "Cesnet1993.graphml",
    "Singaren": "Singaren.graphml",
    "Arpanet19706": "Arpanet19706.graphml",
    "Cesnet1997": "Cesnet1997.graphml",
    "Eenet": "Eenet.graphml",
    "Twaren": "Twaren.graphml",
    "Atmnet": "Atmnet.graphml",

    # Medium networks (30-100 nodes)
    "Geant2012": "Geant2012.graphml",
    "Chinanet": "Chinanet.graphml",
    "Surfnet": "Surfnet.graphml",
    "Uunet": "Uunet.graphml",
    "Ntt": "Ntt.graphml",
    "BtNorthAmerica": "BtNorthAmerica.graphml",
    "Palmetto": "Palmetto.graphml",
    "SwitchL3": "SwitchL3.graphml",
    "DeutscheTelekom": "DeutscheTelekom.graphml",
    "Iij": "Iij.graphml",

    # Large networks (> 100 nodes)
    "Interoute": "Interoute.graphml",
    "Colt": "Colt.graphml",
    "GtsCe": "GtsCe.graphml",
    "TataNld": "TataNld.graphml",
    "UsCarrier": "UsCarrier.graphml",
    "Deltacom": "Deltacom.graphml",
    "Ion": "Ion.graphml",
    "Pern": "Pern.graphml",
    "Cogentco": "Cogentco.graphml",
    "DialtelecomCz": "DialtelecomCz.graphml",
}
GRAPH_FILES = [os.path.join(GRAPH_DIR, fname) for fname in topo.values()]

# ==============================================================
# 1. ACADEMICALLY-JUSTIFIED BUDGET FUNCTION
# ==============================================================

def edge_budget(n: int, m: int) -> int:
    """
    Budget B(N,M) = clamp( ceil(0.15 N), 2, min( ceil(0.1 M), 20 ) )

    Justification:
      - 0.15 N   : scale with number of nodes (per-node upgrade budget),
                   10–20% modifications are common in design studies.
      - 0.1 M    : do not add more than 10% of existing edges to keep
                   augmentation realistic from an engineering perspective.
      - cap at 20: keeps RL search tractable even on large backbones.
    """
    node_based = int(np.ceil(0.15 * n))
    edge_based = int(np.ceil(0.10 * m))
    upper = min(edge_based if edge_based > 0 else 20, 20)
    return max(2, min(node_based, upper))

# ==============================================================
# 2. ENVIRONMENT WITH TRUE IVI, TRUE NNSI, HYBRID (γ=5)
# ==============================================================

class ResilienceEnv(gym.Env):
    """
    RL environment: add edges under a fixed budget to improve robustness.
    """
    Reward types:
  - 'ivi'        : reduce max IVI (Integrated Value of Influence)
      - 'nnsi'       : reduce max NNSI (Network Node Significance Index)
      - 'hybrid'     : λ₂-safe IVI:
                       r = ΔIVI - γ * max(0, -Δλ₂)
      - 'effres_l2'  : Effective graph resistance + λ₂ shaping:
                       r = δ * ΔEffRes_rel + β * max(0, Δλ₂) - γ * max(0, -Δλ₂)
                       where ΔEffRes_rel = (EffRes_prev - EffRes_curr) / (|EffRes_prev| + ε)


    metadata = {"render_modes": []}

    def __init__(self, path, reward_type="hybrid", budget_edges=None, gamma=5.0, beta=1.0, delta=1.0):
        super().__init__()
        g = ig.Graph.Read_GraphML(path).as_undirected()
        self.g_orig = g.copy()
        self.n = g.vcount()
        self.m = g.ecount()
        assert reward_type in ["ivi", "nnsi", "hybrid", "effres_l2"]
        self.reward_type = reward_type
        self.gamma = gamma
        self.beta = beta
        self.delta = delta

        # Budget
        if budget_edges is None:
            self.budget = edge_budget(self.n, self.m)
        else:
            self.budget = budget_edges

        # Candidate edges = all missing edges
        existing = set(tuple(sorted(e)) for e in g.get_edgelist())
        self.candidates = [
            (i, j)
            for i in range(self.n)
            for j in range(i + 1, self.n)
            if (i, j) not in existing
        ]
        self.action_space = spaces.Discrete(len(self.candidates))

        # Node features: 5 per node (deg, closeness, PR, core, clustering)
        self.observation_space = spaces.Box(
            low=-5, high=5, shape=(self.n * 5,), dtype=np.float32
        )

        # Precompute normalization stats on original graph
        feats = self._compute_node_features(self.g_orig)
        self.mean, self.std = feats.mean(0), feats.std(0) + 1e-8

        # Static symmetric edge index for GNN (original topology)
        edges = g.get_edgelist()
        ei = torch.tensor(edges, dtype=torch.long).t()          # [2, E]
        self.edge_index_base = torch.cat([ei, ei.flip(0)], dim=1)  # undirected

        # Track added edges
        self.added_edges = set()

        self.reset()

    # ---------- node features for observations ----------
    def _compute_node_features(self, g: ig.Graph):
        n = g.vcount()
        deg = np.array(g.degree(), dtype=float)
        try:
            close_raw = g.closeness()
            close = np.array(close_raw, dtype=float)
        except:
            close = np.zeros(n, dtype=float)
        pr = np.array(g.pagerank(), dtype=float)
        core = np.array(g.coreness(), dtype=float)
        clust = np.array(g.transitivity_local_undirected(mode="zero"), dtype=float)
        return np.stack([deg, close, pr, core, clust], axis=1).astype(np.float32)

    # ---------- helper: min-max scaling ----------
    @staticmethod
    def _minmax(x: np.ndarray):
        x = np.asarray(x, dtype=float)
        if x.size == 0:
            return x
        rng = x.max() - x.min()
        if rng <= 1e-12:
            return np.zeros_like(x)
        return (x - x.min()) / (rng + 1e-12)

    # ---------- H-index & local H-index ----------
    def _h_index_vec(self, deg: np.ndarray, g: ig.Graph):
        n = g.vcount()
        H = np.zeros(n, dtype=float)
        for v in range(n):
            neigh = g.neighbors(v)
            if not neigh:
                continue
            d = np.sort(deg[neigh])[::-1]
            h = 0
            for i, val in enumerate(d, start=1):
                if val >= i:
                    h = i
                else:
                    break
            H[v] = h
        return H

    def _local_h_index_vec(self, H: np.ndarray, g: ig.Graph):
        n = g.vcount()
        LH = np.zeros(n, dtype=float)
        for v in range(n):
            neigh = g.neighbors(v)
            LH[v] = H[v] + H[neigh].sum() if neigh else H[v]
        return LH

    # ---------- neighborhood connectivity ----------
    def _neighborhood_connectivity(self, deg: np.ndarray, g: ig.Graph):
        n = g.vcount()
        NC = np.zeros(n, dtype=float)
        for v in range(n):
            neigh = g.neighbors(v)
            if not neigh:
                continue
            NC[v] = deg[neigh].mean()
        return NC

    # ---------- ClusterRank (Chen et al. 2013) ----------
    def _cluster_rank(self, deg: np.ndarray, clust: np.ndarray, g: ig.Graph):
        """
        CR_i = f(c_i) * sum_{j in N(i)} (k_j + 1)
        with f(c_i) = 10^{c_i} for undirected graphs.
        """
        n = g.vcount()
        CR = np.zeros(n, dtype=float)
        f_c = 10.0 ** clust
        for v in range(n):
            neigh = g.neighbors(v)
            if not neigh:
                continue
            CR[v] = f_c[v] * np.sum(deg[neigh] + 1.0)
        return CR

    # ---------- Collective Influence (ℓ = 2) ----------
    def _collective_influence(self, deg: np.ndarray, g: ig.Graph, ell: int = 2):
        """
        CI_ell(i) = (k_i - 1) * sum_{j in ∂B(i, ell)} (k_j - 1)
        Here ell = 2, boundary approximated as nodes at distance exactly 2.
        """
        n = g.vcount()
        CI = np.zeros(n, dtype=float)
        for v in range(n):
            k_i = deg[v]
            if k_i <= 1:
                continue
            one_hop = set(g.neighbors(v))
            two_hop = set()
            for u in one_hop:
                two_hop.update(g.neighbors(u))
            two_hop.discard(v)
            two_hop.difference_update(one_hop)
            if not two_hop:
                continue
            CI[v] = (k_i - 1.0) * np.sum(deg[list(two_hop)] - 1.0)
        return CI

    # ---------- True IVI ----------
    def _ivi_scores(self, g: ig.Graph):
        n = g.vcount()
        deg = np.array(g.degree(), dtype=float)
        clust = np.array(g.transitivity_local_undirected(mode="zero"), dtype=float)
        NC = self._neighborhood_connectivity(deg, g)
        H = self._h_index_vec(deg, g)
        LH = self._local_h_index_vec(H, g)
        BC = np.array(g.betweenness(), dtype=float)
        CI = self._collective_influence(deg, g, ell=2)

        CR = self._cluster_rank(deg, clust, g)

        DC0 = self._minmax(deg)
        LH0 = self._minmax(LH)
        NC0 = self._minmax(NC)
        CR0 = self._minmax(CR)
        BC0 = self._minmax(BC)
        CI0 = self._minmax(CI)

        hub = DC0 + LH0                     # Hubness score
        spread = (NC0 + CR0) / (BC0 + CI0 + 1e-8)  # Spreading score
        ivi = hub * spread                  # IVI = Hubness * Spreading
        return ivi

    # ---------- True NNSI ----------
    def _nnsi_scores(self, g: ig.Graph):
        n = g.vcount()
        deg = np.array(g.degree(), dtype=float)
        close = np.array(g.closeness() or [0.0] * n, dtype=float)
        BC = np.array(g.betweenness(), dtype=float)
        core = np.array(g.coreness(), dtype=float)        # K-core
        pr = np.array(g.pagerank(), dtype=float)
        CI = self._collective_influence(deg, g, ell=2)

        DC0 = self._minmax(deg)
        CC0 = self._minmax(close)
        BC0 = self._minmax(BC)
        K0  = self._minmax(core)
        PR0 = self._minmax(pr)
        CI0 = self._minmax(CI)

        CS  = DC0 + CC0          # Connectivity Score
        FCS = BC0 + K0           # Flow Control Score
        IPS = PR0 + CI0          # Influence Propagation Score

        nnsi = CS * FCS * IPS    # NNSI = CS * FCS * IPS
        return nnsi

    # ---------- λ₂ surrogate from degrees ----------
    def _approx_lambda2(self, g: ig.Graph):
        d = np.array(g.degree(), dtype=float)
        if d.size < 2:
            return 0.0
        d_mean = d.mean()
        d2_mean = (d ** 2).mean()
        var = max(0.0, d2_mean - d_mean ** 2)
        return max(0.0, d_mean - np.sqrt(var))

    def _effective_graph_resistance(self, g: ig.Graph):
        """Effective graph resistance (Kirchhoff index), a robustness metric.

        R_G = n * sum_{i=2..n} 1/λ_i where λ_i are Laplacian eigenvalues.
        For disconnected graphs, R_G is unbounded, we return a large value.
        """
        n = g.vcount()
        if n <= 1:
            return 0.0

        # Disconnected => unbounded effective resistance
        try:
            if not g.is_connected():
                return 1e9
        except Exception:
            # If connectivity check fails, be conservative
            return 1e9

        L = np.array(g.laplacian(), dtype=float)
        evals = np.linalg.eigvalsh(L)
        evals.sort()

        nonzero = evals[1:]
        nonzero = nonzero[nonzero > 1e-12]
        if nonzero.size == 0:
            return 1e9

        return float(n * np.sum(1.0 / nonzero))

    # ---------- Gym API ----------
    def reset(self, seed=None, options=None):
        super().reset(seed=seed)
        self.g = self.g_orig.copy()
        self.added_edges = set()
        self.steps = 0

        # Baselines for rewards
        self.prev_lambda2 = self._approx_lambda2(self.g)
        self.prev_mincut  = self.g.mincut_value()
        self.prev_max_ivi = self._ivi_scores(self.g).max()
        self.prev_max_nnsi = self._nnsi_scores(self.g).max()        self.prev_effres = self._effective_graph_resistance(self.g) if self.reward_type == "effres_l2" else None


        obs = self._obs()
        return obs, {}

    def _obs(self):
        feats = self._compute_node_features(self.g)
        return ((feats - self.mean) / self.std).flatten().astype(np.float32)

    def step(self, action):
        u, v = self.candidates[action]
        edge = tuple(sorted((u, v)))

        # No-op: already present or already added
        if edge in self.added_edges or self.g.are_connected(u, v):
            reward = -0.5
        else:
            self.g.add_edge(u, v)
            self.added_edges.add(edge)
            reward = self._compute_reward()

        self.steps += 1
        done = self.steps >= self.budget
        obs = self._obs()
        return obs, float(reward), done, False, {}

    def _compute_reward(self):
        # Current metrics
        curr_lambda2 = self._approx_lambda2(self.g)
        curr_mincut  = self.g.mincut_value()
        curr_max_ivi = self._ivi_scores(self.g).max()
        curr_max_nnsi = self._nnsi_scores(self.g).max()
        curr_effres = self._effective_graph_resistance(self.g) if self.reward_type == \"effres_l2\" else None

        # Deltas
        d_lambda2 = curr_lambda2 - self.prev_lambda2
        d_ivi     = self.prev_max_ivi  - curr_max_ivi      # >0 => IVI improved
        d_nnsi    = self.prev_max_nnsi - curr_max_nnsi     # >0 => NNSI improved

        if self.reward_type == \"effres_l2\":
            prev = float(self.prev_effres) if self.prev_effres is not None else 1e9
            d_effres = (prev - float(curr_effres)) / (abs(prev) + 1e-9)

        if self.reward_type == "ivi":
            r = d_ivi
        elif self.reward_type == "nnsi":
            r = d_nnsi
        elif self.reward_type == "effres_l2":
            lambda_bonus   = self.beta  * max(0.0, d_lambda2)
            lambda_penalty = self.gamma * max(0.0, -d_lambda2)
            r = self.delta * d_effres + lambda_bonus - lambda_penalty
        else:  # "hybrid" -> λ₂-safe IVI
            penalty = self.gamma * max(0.0, -d_lambda2)  # only when λ₂ decreases
            r = d_ivi - penalty

        # Update baselines for next step
        self.prev_lambda2 = curr_lambda2
        self.prev_mincut  = curr_mincut
        self.prev_max_ivi = curr_max_ivi
        self.prev_max_nnsi = curr_max_nnsi
        if self.reward_type == "effres_l2":
            self.prev_effres = float(curr_effres)


        # Clamp for DQN stability
        return max(min(r, 5.0), -5.0)

# --------------------- CLEAN GNN EXTRACTOR ---------------------
class CleanGNNExtractor(BaseFeaturesExtractor):
    """
    GraphConv-based extractor:
      - obs is flattened node feature matrix [B, N*5]
      - uses fixed edge_index passed via policy_kwargs
    """

    def __init__(self, observation_space, edge_index, features_dim=128):
        super().__init__(observation_space, features_dim)
        self.n_nodes = observation_space.shape[0] // 5

        # Ensure edge_index moves with the model to GPU/CPU
        self.register_buffer("edge_index", edge_index)

        self.gnn = pyg_nn.Sequential("x, edge_index", [
            (pyg_nn.GraphConv(5, 64), "x, edge_index -> x"),
            nn.ReLU(),
            (pyg_nn.GraphConv(64, 64), "x, edge_index -> x"),
            nn.ReLU(),
            (pyg_nn.GraphConv(64, 32), "x, edge_index -> x"),
        ])
        self.pool = pyg_nn.global_mean_pool
        self.proj = nn.Linear(32, features_dim)

    def forward(self, obs: torch.Tensor) -> torch.Tensor:
        b = obs.shape[0]
        x = obs.view(b, self.n_nodes, 5).view(-1, 5)  # [B*N, 5]
        x = self.gnn(x, self.edge_index)
        batch = torch.arange(b, device=obs.device).repeat_interleave(self.n_nodes)
        x = self.pool(x, batch)
        x = self.proj(x)
        return x

# ==============================================================
# 3. MULTI-METRIC EXACT EVALUATION
# ==============================================================

def exact_metrics(g: ig.Graph):
    """
    Multi-metric evaluation of a graph.
    """
    n = g.vcount()
    if n < 2:
        return {
            "λ₂": 0.0,
            "MinCut": 0.0,
            "GCC_5%": 1.0,
            "ASPL": 0.0,
            "Diameter": 0.0,
            "ArticulationPoints": 0,
            "Bridges": 0,
            "BetCentralization": 0.0,
            "NatConnectivity": 0.0,
        }

    # λ₂ (algebraic connectivity)
    L = np.array(g.laplacian(normalized=True))
    eigs = np.sort(np.linalg.eigvalsh(L))
    lambda2 = eigs[1] if len(eigs) > 1 else 0.0

    # Min-cut
    mincut = g.mincut_value()

    # GCC after targeted attack (top 5% degree nodes)
    k = max(1, int(0.05 * n))
    top_deg = np.argsort(-np.array(g.degree()))[:k]
    gc = g.copy()
    gc.delete_vertices(top_deg)
    try:
        gcc = gc.clusters().giant().vcount() / max(1, (n - k))
    except:
        gcc = 0.0

    # Average shortest path length & diameter
    try:
        aspl = g.average_path_length()
    except:
        aspl = np.inf
    diam = g.diameter() if g.is_connected() else np.inf

    # Articulation points & bridges
    art_pts = len(g.articulation_points())
    bridges = len(g.bridges())

    # Betweenness centralization (simple normalization)
    bet = np.array(g.betweenness())
    if n > 2:
        bet_central = (bet.max() * (n - 1)) / ((n - 1) * (n - 2) / 2)
    else:
        bet_central = 0.0

    # Natural connectivity
    A = np.array(g.get_adjacency().data)
    eigA = np.linalg.eigvals(A)
    natconn = float(np.log(np.mean(np.exp(eigA.real)) + 1e-12))

    return {
        "λ₂": float(lambda2),
        "MinCut": float(mincut),
        "GCC_5%": float(gcc),
        "ASPL": float(aspl),
        "Diameter": float(diam),
        "ArticulationPoints": int(art_pts),
        "Bridges": int(bridges),
        "BetCentralization": float(bet_central),
        "NatConnectivity": float(natconn),
    }

# ==============================================================
# 4. MAIN EXPERIMENT LOOP – IVI, NNSI, HYBRID (γ = 5)
# ==============================================================

results = []
metrics = [
    "λ₂", "MinCut", "GCC_5%", "ASPL", "Diameter",
    "ArticulationPoints", "Bridges", "BetCentralization", "NatConnectivity"
]

for path in tqdm(GRAPH_FILES, desc="Graphs"):
    name = os.path.basename(path).split(".")[0]
    orig_g = ig.Graph.Read_GraphML(path).as_undirected()
    n, m = orig_g.vcount(), orig_g.ecount()

    # Original metrics
    orig_met = exact_metrics(orig_g)
    row = {"Graph": name, "N": n, "M": m}

    for k, v in orig_met.items():
        row[f"Orig_{k}"] = v

    # Shared budget
    B = edge_budget(n, m)
    row["BudgetEdges"] = B

    # RL methods
    for reward_type in ["ivi", "nnsi", "hybrid"]:
        env = ResilienceEnv(path, reward_type=reward_type, budget_edges=B, gamma=5.0)

        base_ei = env.edge_index_base.clone()
        policy_kwargs = dict(
            features_extractor_class=CleanGNNExtractor,
            features_extractor_kwargs=dict(edge_index=base_ei),
            net_arch=[256, 256],
        )

        model = DQN(
            "MlpPolicy",
            env,
            policy_kwargs=policy_kwargs,
            learning_rate=2e-3,
            buffer_size=50000,
            batch_size=128,
            learning_starts=1000,
            train_freq=4,
            target_update_interval=1000,
            gamma=0.98,
            device=DEVICE,
            verbose=0,
            seed=SEED,
        )

        model.learn(total_timesteps=25000)

        # Final rollout
        obs, _ = env.reset()
        for _ in range(env.budget):
            action, _ = model.predict(obs, deterministic=True)
            obs, _, done, _, _ = env.step(action)
            if done:
                break

        final_met = exact_metrics(env.g)
        prefix = reward_type.upper()
        for k, v in final_met.items():
            row[f"{prefix}_{k}"] = v

    results.append(row)

df = pd.DataFrame(results)

# ==============================================================
# 5. COMPUTE %Δ VS ORIGINAL & HYBRID VS IVI/NNSI
# ==============================================================

for k in metrics:
    orig_col = f"Orig_{k}"
    for r in ["IVI", "NNSI", "HYBRID"]:
        col = f"{r}_{k}"
        df[f"%Δ_{r}_vs_Orig_{k}"] = (
            (df[col] - df[orig_col]) / (df[orig_col].abs() + 1e-8) * 100
        ).round(2)

    # HYBRID vs IVI, HYBRID vs NNSI
    df[f"%Δ_HYBRID_vs_IVI_{k}"] = (
        (df[f"HYBRID_{k}"] - df[f"IVI_{k}"]) /
        (df[f"IVI_{k}"].abs() + 1e-8) * 100
    ).round(2)

    df[f"%Δ_HYBRID_vs_NNSI_{k}"] = (
        (df[f"HYBRID_{k}"] - df[f"NNSI_{k}"]) /
        (df[f"NNSI_{k}"].abs() + 1e-8) * 100
    ).round(2)

print("\n============================================================")
print("FINAL RL-ONLY RESULTS – IVI / NNSI / HYBRID (γ=5)")
print("============================================================\n")

core_cols = ["Graph", "N", "M", "BudgetEdges"]
for k in ["λ₂", "GCC_5%", "NatConnectivity", "ASPL", "Diameter"]:
    core_cols += [
        f"%Δ_IVI_vs_Orig_{k}",
        f"%Δ_NNSI_vs_Orig_{k}",
        f"%Δ_HYBRID_vs_Orig_{k}",
        f"%Δ_HYBRID_vs_IVI_{k}",
        f"%Δ_HYBRID_vs_NNSI_{k}",
    ]

display(df[core_cols])

# ==============================================================
# 6. SAVE TO DRIVE
# ==============================================================

out_csv = "/content/drive/MyDrive/thesis_rl_multimetric_30graphs.csv"
df.to_csv(out_csv, index=False)
print(f"\nSaved: {out_csv}")



